# Hugging Face Environment Variables
# Copy this file to .env and fill in your values

# Hugging Face Hub Token (for private models and increased rate limits)
# Get your token from: https://huggingface.co/settings/tokens
HUGGINGFACE_HUB_TOKEN=your_token_here

# Weights & Biases API Key (for experiment tracking)
# Get your key from: https://wandb.ai/authorize
WANDB_API_KEY=your_wandb_key_here

# Model Cache Directory (optional - defaults to ~/.cache/huggingface)
HF_HOME=/workspaces/huggingface/models/.cache

# Device Configuration
# Options: auto, cpu, cuda, cuda:0, cuda:1, etc.
DEVICE=auto

# Default Model Settings
DEFAULT_TEXT_MODEL=gpt2
DEFAULT_CLASSIFICATION_MODEL=cardiffnlp/twitter-roberta-base-sentiment-latest
DEFAULT_QA_MODEL=distilbert-base-cased-distilled-squad

# Generation Parameters
DEFAULT_MAX_LENGTH=100
DEFAULT_TEMPERATURE=0.7
DEFAULT_TOP_P=0.9

# Quantization Settings (for large models)
USE_QUANTIZATION=false
QUANTIZATION_BITS=4

# Gradio Interface Settings
GRADIO_PORT=7860
GRADIO_SHARE=false

# Logging Level (DEBUG, INFO, WARNING, ERROR)
LOG_LEVEL=INFO

# OpenAI API Key (if using OpenAI models for comparison)
# OPENAI_API_KEY=your_openai_key_here

# Anthropic API Key (if using Claude models)
# ANTHROPIC_API_KEY=your_anthropic_key_here