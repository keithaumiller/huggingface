{
  "project_name": "huggingface-llm-workspace",
  "description": "A comprehensive workspace for working with Hugging Face large language models",
  "version": "1.0.0",
  
  "models": {
    "text_generation": {
      "small": ["gpt2", "distilgpt2"],
      "medium": ["gpt2-medium", "microsoft/DialoGPT-medium"],
      "large": ["gpt2-large", "gpt2-xl"],
      "instruction_tuned": ["microsoft/DialoGPT-large"]
    },
    "classification": {
      "sentiment": [
        "cardiffnlp/twitter-roberta-base-sentiment-latest",
        "distilbert-base-uncased-finetuned-sst-2-english"
      ],
      "emotion": ["j-hartmann/emotion-english-distilroberta-base"],
      "topic": ["facebook/bart-large-mnli"]
    },
    "question_answering": {
      "general": ["distilbert-base-cased-distilled-squad"],
      "conversational": ["deepset/roberta-base-squad2"]
    },
    "named_entity_recognition": {
      "general": ["dbmdz/bert-large-cased-finetuned-conll03-english"],
      "biomedical": ["d4data/biomedical-ner-all"]
    }
  },
  
  "default_settings": {
    "generation": {
      "max_length": 100,
      "temperature": 0.7,
      "top_p": 0.9,
      "do_sample": true,
      "num_return_sequences": 1
    },
    "classification": {
      "return_all_scores": false,
      "top_k": 1
    },
    "question_answering": {
      "max_answer_len": 30,
      "max_question_len": 64,
      "max_seq_len": 384
    }
  },
  
  "hardware_requirements": {
    "minimum": {
      "ram_gb": 8,
      "storage_gb": 10,
      "gpu_memory_gb": 0
    },
    "recommended": {
      "ram_gb": 16,
      "storage_gb": 50,
      "gpu_memory_gb": 8
    },
    "optimal": {
      "ram_gb": 32,
      "storage_gb": 100,
      "gpu_memory_gb": 16
    }
  },
  
  "quantization": {
    "supported_bits": [4, 8, 16],
    "default_bits": 4,
    "compute_dtype": "float16",
    "quant_type": "nf4"
  },
  
  "cache_settings": {
    "model_cache_dir": "models/.cache",
    "dataset_cache_dir": "data/.cache",
    "max_cache_size_gb": 50
  },
  
  "api_endpoints": {
    "huggingface_hub": "https://huggingface.co",
    "inference_api": "https://api-inference.huggingface.co/models/"
  },
  
  "supported_tasks": [
    "text-generation",
    "text-classification",
    "question-answering",
    "named-entity-recognition",
    "summarization",
    "translation",
    "fill-mask",
    "token-classification"
  ],
  
  "example_prompts": {
    "creative_writing": [
      "Once upon a time in a distant galaxy",
      "The last person on Earth sat alone in a room. There was a knock on the door.",
      "In the year 2050, artificial intelligence had become"
    ],
    "technical_writing": [
      "The advantages of using transformer models include",
      "Machine learning can be applied to solve problems such as",
      "The future of renewable energy technology involves"
    ],
    "conversational": [
      "Hello, how are you doing today?",
      "What's the weather like?",
      "Can you help me with a question about programming?"
    ]
  }
}